{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4882d7af-e181-4e25-a5a8-7b9a7f78e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c4dac8-5fac-4f6a-9261-3c46d690979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data :  130\n",
      "Vocabulary size :  24\n",
      "Vocabulary :  {'e', 'p', 'u', 'd', 's', 'h', 'T', 'a', '.', 't', 'm', 'g', 'v', 'w', 'b', ',', 'l', 'k', 'i', 'y', 'n', 'r', 'o', ' '}\n"
     ]
    }
   ],
   "source": [
    "file_data = open('data_cllm1.txt','r').read()\n",
    "data = list(file_data)\n",
    "vocab = set(file_data)\n",
    "data_size , vocab_size = len(data) , len(vocab)\n",
    "print('length of data : ',data_size)\n",
    "print('Vocabulary size : ',vocab_size)\n",
    "print('Vocabulary : ',vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d256c9-ed86-4293-a2b8-562902fe5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_chr = {ix : ch for ix,ch in enumerate(vocab)}\n",
    "chr_to_ix = {ch : ix for ix,ch in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a73977-4544-4b93-a9c7-5f1efccd8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the rnn model with 100 neurons in the hidden layer\n",
    "hidden_neurons = 30\n",
    "sequence_length = 5\n",
    "# hyperparameters : Normalization\n",
    "w_xh = np.random.randn(hidden_neurons,vocab_size) * 0.01 # input to hidden neurons\n",
    "w_hh = np.random.randn(hidden_neurons,hidden_neurons) * 0.01 # hidden to hidden\n",
    "w_hy = np.random.randn(vocab_size,hidden_neurons) * 0.01 # hidden to output\n",
    "b_h = np.zeros((hidden_neurons,1))\n",
    "b_y = np.zeros((vocab_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab73fc5-f99b-4bbd-99d4-1c7991c7ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_and_loss(inputs,targets,h_previous):\n",
    "    x_states = {}\n",
    "    h_states = {}\n",
    "    y_states = {}\n",
    "    prob_logits = {}\n",
    "    h_states[-1] = h_previous  # initial hidden state before time stamp = 1\n",
    "    # feeding the inputs\n",
    "    loss = 0\n",
    "    for t in range(len(inputs)):\n",
    "        x_states[t] = np.zeros((vocab_size,1))\n",
    "        x_states[t][inputs[t]] = 1\n",
    "        h_states[t] = np.tanh(np.dot(w_xh,x_states[t]) + np.dot(w_hh,h_states[t-1]) + b_h)\n",
    "        y_states[t] = np.dot(w_hy,h_states[t]) + b_y\n",
    "        # probability distributions of the output :  softmax\n",
    "        prob_logits[t] = np.exp(y_states[t])/np.sum(np.exp(y_states[t]))\n",
    "        # summing up losses at each time stamp\n",
    "        # cross entropy loss\n",
    "        loss += -np.log(prob_logits[t][targets[t],0])\n",
    "\n",
    "        # computing loss\n",
    "    dw_xh = np.zeros_like(w_xh)\n",
    "    dw_hh = np.zeros_like(w_hh)\n",
    "    dw_hy = np.zeros_like(w_hy)\n",
    "    db_h = np.zeros_like(b_h)\n",
    "    db_y = np.zeros_like(b_y)\n",
    "    #losses of the future time stamps as the loss wrt hidden state also influence the future hidden states \n",
    "    dhnext = np.zeros_like(b_h) \n",
    "    for t in reversed(range(len(inputs))):\n",
    "        # calculating loss wrt output\n",
    "        # dy = dL/dy\n",
    "        dy = np.copy(prob_logits[t])  # same as the probabilities if not target class\n",
    "        dy[targets[t]] -= 1 # Loss = probability - 1 if target class  \n",
    "        dw_hy += np.dot(dy,h_states[t].T) # dL/dwhy = dL/dy * dy/dwhy\n",
    "        db_y += dy                 # dL/dby = dL/dy * dy/dby\n",
    "        # calculating loss wrt hidden state\n",
    "        # dh(t) = dL/dy * dy/dh  + gradient wrt the future time stamps \n",
    "        dh = np.dot(w_hy.T,dy) + dhnext\n",
    "        # backpropagating in the tanh non-linearity in hidden states\n",
    "        # dh(z)/dp = (1 - h(z)^2) * dz/dp  where z is the input to the hidden state\n",
    "        dhraw = (1 - h_states[t]**2) * dh\n",
    "        db_h += dhraw\n",
    "        dw_hh += np.dot(dhraw,h_states[t-1].T)\n",
    "        dw_xh += np.dot(dhraw,x_states[t].T)\n",
    "        # updating the gradients wrt the future hidden states\n",
    "        # dL/dh(t+1)\n",
    "        dhnext += np.dot(w_hh.T,dhraw)\n",
    "    # clipping to prevent exploding gradients\n",
    "    for dpara in [dw_xh,dw_hh,dw_hy,db_h,db_y]:\n",
    "        np.clip(dpara,-5,5,out=dpara)\n",
    "    return loss,dw_xh,dw_hh,dw_hy,db_h,db_y,h_states[len(inputs)-1]  # last hidden states the sequence input\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa7ef947-6572-4bb9-b80f-48be7787d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_sequence(hidden_state,seed,n):\n",
    "    x = np.zeros((vocab_size,1))\n",
    "    x[seed] = 1\n",
    "    out = [ix_to_chr[seed]]\n",
    "    # generating output : \n",
    "    for t in range(n):\n",
    "        hidden_state = np.tanh(np.dot(w_xh,x) + np.dot(w_hh,hidden_state) + b_h)\n",
    "        y_out = np.dot(w_hy,hidden_state) + b_y\n",
    "        y_out_p = np.exp(y_out)/np.sum(np.exp(y_out))\n",
    "        # find selection of the next character : \n",
    "        ix = np.random.choice(range(vocab_size),p = y_out_p.ravel())  # ravel is used for flatting\n",
    "        x = np.zeros_like(x)\n",
    "        x[ix] = 1\n",
    "        out.append(ix_to_chr[ix])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f908a580-8b83-4dda-a5c6-92f2a308397e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      " Tnmuoggotk,m,evt,mv knpkoehwvlbTilbwlop,hrtm,vys.ah ---\n",
      "\n",
      "--iter--0\t\t--loss--15.890268530596474\n",
      "---\n",
      " Twitwotwinwtat y................................... ---\n",
      "\n",
      "--iter--1000\t\t--loss--9.261540183866181\n",
      "---\n",
      " Twinkle littt.ondee why............................ ---\n",
      "\n",
      "--iter--2000\t\t--loss--3.982216913179254\n",
      "---\n",
      " Twinkle thiwhnkle little star, hoa diamond in  ite  ---\n",
      "\n",
      "--iter--3000\t\t--loss--1.8313867181335064\n",
      "---\n",
      " Twinkle twinkle lideattbove adero high, like lditt  ---\n",
      "\n",
      "--iter--4000\t\t--loss--0.8772979656197974\n",
      "---\n",
      " Twinkle twinkle twinkle t.inkthe lia lit yky....... ---\n",
      "\n",
      "--iter--5000\t\t--loss--0.49518371132665595\n",
      "---\n",
      " Twinkle little st igve lherlyt sky................. ---\n",
      "\n",
      "--iter--6000\t\t--loss--0.3137277541019518\n",
      "---\n",
      " Twinkle litle stwoow i wonder wha dore .habore t yo ---\n",
      "\n",
      "--iter--7000\t\t--loss--0.21469563782771633\n",
      "---\n",
      " Twinkle twinkle litle star, how i sowibwon lee s... ---\n",
      "\n",
      "--iter--8000\t\t--loss--0.1597420472040857\n",
      "---\n",
      " Twinkle twind hotle wiat you diamond in the soatwbo ---\n",
      "\n",
      "--iter--9000\t\t--loss--0.1175721801354935\n",
      "---\n",
      " Twinkle little star, how i wonder what you are, up  ---\n",
      "\n",
      "--iter--10000\t\t--loss--0.09467647839296402\n",
      "---\n",
      " Twinklee what you are, up above the sky............ ---\n",
      "\n",
      "--iter--11000\t\t--loss--0.0944859364720566\n",
      "---\n",
      " Twinkle twinkle little star, howe w nwle little sta ---\n",
      "\n",
      "--iter--12000\t\t--loss--0.10398467245077736\n",
      "---\n",
      " Twinklen le litttt u arigkled s.................... ---\n",
      "\n",
      "--iter--13000\t\t--loss--0.08353030214320929\n",
      "---\n",
      " Twinkle twinkle littli s lit sklt iikeo d ar,thow i ---\n",
      "\n",
      "--iter--14000\t\t--loss--0.07541558852605752\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--15000\t\t--loss--0.06342179884603795\n",
      "---\n",
      " Twinkle twinkle, liae nkle little star, how i wonde ---\n",
      "\n",
      "--iter--16000\t\t--loss--0.058561854548988795\n",
      "---\n",
      " Twinkle twin star, how igwonder what you are, up ab ---\n",
      "\n",
      "--iter--17000\t\t--loss--0.2873252000785555\n",
      "---\n",
      " Twinkle twinkle little stard how a wonkee  high, li ---\n",
      "\n",
      "--iter--18000\t\t--loss--0.15301895639945576\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--19000\t\t--loss--0.0897141412332313\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--20000\t\t--loss--0.05963748453094358\n",
      "---\n",
      " Twinkle twinkle little star, hou inkve the sky..... ---\n",
      "\n",
      "--iter--21000\t\t--loss--0.04507228944211225\n",
      "---\n",
      " Twinkle twinkle little star, hoa diamond in the wir ---\n",
      "\n",
      "--iter--22000\t\t--loss--0.03741535315038972\n",
      "---\n",
      " Twonwon st high, like t inkve the world so high, li ---\n",
      "\n",
      "--iter--23000\t\t--loss--0.03282836707645532\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--24000\t\t--loss--0.029880141818576525\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder wiat you  ---\n",
      "\n",
      "--iter--25000\t\t--loss--0.02803342854176096\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--26000\t\t--loss--0.026794047499807728\n",
      "---\n",
      " Twinkle twinkle little star,whn little star, how i  ---\n",
      "\n",
      "--iter--27000\t\t--loss--0.02557661436162802\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--28000\t\t--loss--0.024173122300799797\n",
      "---\n",
      " Twinkle twinkle little stare wow i higwow a stweb s ---\n",
      "\n",
      "--iter--29000\t\t--loss--0.0227946353608651\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--30000\t\t--loss--0.021621482193831257\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--31000\t\t--loss--0.02066976073843224\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--32000\t\t--loss--0.019922004901720913\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--33000\t\t--loss--0.01940416817696188\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--34000\t\t--loss--0.019140460905546105\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--35000\t\t--loss--0.0190445544520627\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--36000\t\t--loss--0.01872961040183651\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--37000\t\t--loss--0.018316297182077834\n",
      "---\n",
      " Twinkle twinkle thi howh, winkle the skve thi so hi ---\n",
      "\n",
      "--iter--38000\t\t--loss--0.017816908612479056\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder wkei  hi  ---\n",
      "\n",
      "--iter--39000\t\t--loss--0.20126793750049976\n",
      "---\n",
      " Twindle  itwe whatle slinkle little star, up ar, ho ---\n",
      "\n",
      "--iter--40000\t\t--loss--0.130863516920832\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--41000\t\t--loss--0.08008594389139659\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--42000\t\t--loss--0.05072147882706422\n",
      "---\n",
      " T.................................................. ---\n",
      "\n",
      "--iter--43000\t\t--loss--0.036153621860428725\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--44000\t\t--loss--0.028462361793043962\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what so h ---\n",
      "\n",
      "--iter--45000\t\t--loss--0.023916113018618526\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--46000\t\t--loss--0.021076095610695\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--47000\t\t--loss--0.01911570269518681\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--48000\t\t--loss--0.01760490987719696\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what youp ---\n",
      "\n",
      "--iter--49000\t\t--loss--0.016375676462789576\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--50000\t\t--loss--0.015352855290855836\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--51000\t\t--loss--0.014480434922192427\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--52000\t\t--loss--0.013706108476211698\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--53000\t\t--loss--0.01300526550793053\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--54000\t\t--loss--0.012384659455770343\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--55000\t\t--loss--0.011850421765963433\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--56000\t\t--loss--0.011396034485003332\n",
      "---\n",
      " Twinkle twinkle little star, how i world so high, l ---\n",
      "\n",
      "--iter--57000\t\t--loss--0.011011630691728407\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--58000\t\t--loss--0.0106867172670815\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--59000\t\t--loss--0.010405568856860283\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--60000\t\t--loss--0.010151491988963576\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--61000\t\t--loss--0.009911747748573644\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--62000\t\t--loss--0.009679086585641237\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--63000\t\t--loss--0.00945043283582955\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--64000\t\t--loss--0.009224623468059955\n",
      "---\n",
      " Twinkle twinkle little star, how i wonder what you  ---\n",
      "\n",
      "--iter--65000\t\t--loss--0.009001880660947214\n"
     ]
    }
   ],
   "source": [
    "# epochs = 1000\n",
    "# epoch = 0\n",
    "pointer = 0  # data pointer initially set to 0 since we'll move from left to right in the data for training\n",
    "iteration = 0 # iteration counter\n",
    "# defining memory of gradients for each hyperparametres as used in adagrad optimization : \n",
    "mwxh = np.zeros_like(w_xh)\n",
    "mwhh = np.zeros_like(w_hh)\n",
    "mwhy = np.zeros_like(w_hy)\n",
    "mbh = np.zeros_like(b_h)\n",
    "mby = np.zeros_like(b_y)\n",
    "smooth_loss = -np.log(1/vocab_size)*sequence_length\n",
    "\n",
    "while True and smooth_loss >= 0.009:\n",
    "    # check if we reached the end of data\n",
    "    if pointer+sequence_length >= data_size or iteration == 0: \n",
    "        # Reset the RNN model i.e, it's hidden states\n",
    "        pointer = 0\n",
    "        h_previous = np.zeros((hidden_neurons,1))\n",
    "        # epoch += 1\n",
    "    # Prepare the inputs and targets\n",
    "    inputs = [chr_to_ix[ch] for ch in data[pointer:pointer+sequence_length]]\n",
    "    targets = [chr_to_ix[ch] for ch in data[pointer+1:pointer+sequence_length+1]]\n",
    "\n",
    "    if iteration % 1000 == 0:\n",
    "        # sample : \n",
    "        sample_ix = Generate_sequence(h_previous,inputs[0],50)\n",
    "        txt = ''.join(sample_ix)\n",
    "        print('---\\n',txt,'---\\n')\n",
    "\n",
    "    # calculate the loss after feeding the inputs to the rnn:\n",
    "    loss,dw_xh,dw_hh,dw_hy,db_h,db_y,h_previous = feed_and_loss(inputs,targets,h_previous)\n",
    "    # exponentially moving average of the loss\n",
    "    smooth_loss = smooth_loss * 0.999 + loss*0.001\n",
    "    if iteration % 1000 == 0:\n",
    "        print(f'--iter--{iteration}\\t\\t--loss--{smooth_loss}')\n",
    "    # updating the hyper parametres using adagrad optimization : \n",
    "    for para , dpara, mem_para in zip([w_xh,w_hh,w_hy,b_h,b_y],[dw_xh,dw_hh,dw_hy,db_h,db_y],[mwxh,mwhh,mwhy,mbh,mby]) : \n",
    "        # updation  in memory : \n",
    "        mem_para += dpara**2\n",
    "        para -= 0.1 * dpara / np.sqrt(mem_para + 1e-8) # adagrad\n",
    "    pointer += sequence_length\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab53774-f066-46ab-a2a1-ea7665b0ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twinkle twinkle little star, how i wonder what you are, up above the world so high, like a diamond in the sky...\n"
     ]
    }
   ],
   "source": [
    "sample_ix = Generate_sequence(np.zeros((hidden_neurons,1)),chr_to_ix['T'],111)\n",
    "txt = ''.join(sample_ix)\n",
    "print(txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
